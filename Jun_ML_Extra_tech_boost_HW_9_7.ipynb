{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jun ML_Extra_tech_boost HW 9.7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oObelix/DataScience/blob/master/Jun_ML_Extra_tech_boost_HW_9_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTnbWDwjNqBj"
      },
      "source": [
        "# Stacking\n",
        "\n",
        "Несмотря на то, что в открытом доступе существует довольно много реализаций стекинга, некоторые из которых даже представлены в виде библиотечных функций, лучше сделать собственную. Стекинг - не классический алгоритм решения задачи, а скорее набор правил для помощи в решении задачи другим алгоритмам. Если вы серьезно займетесь машинным обучением, рано или поздно вам скорее всего захочется что-нибудь поменять в этом наборе правил, поэтому собственная реализация с понятным вам кодом будет как нельзя кстати."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0AKW53hNqBk"
      },
      "source": [
        "В этом домашнем задании вы создадите собственную функцию для блендинга/классического стекинга моделей, которая пригодится вам в дальнейшем.\n",
        "\n",
        "Ниже вы увидите заготовку для функции, где:\n",
        "\n",
        "- models - список объектов базовых алгоритмов\n",
        "\n",
        "- meta_alg - мета-алгоритм\n",
        "\n",
        "data_train, targets_train, data_test, targets_test - тренировочные и тестовые признаки и целевые переменные\n",
        "\n",
        "- test_size - размер тестовых данных для блендинга в промежутке (0, 1)\n",
        "\n",
        "- cv - количество разбиений для кросс-валидации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVIUJhUMNqBl"
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDRkf96PNqBo"
      },
      "source": [
        "def stacking(models, meta_alg, data_train, targets_train, data_test, \n",
        "             targets_test=None, test_size=None, cv=5):\n",
        "    for n, model in enumerate(models):\n",
        "      meta_mtrx[:, n] = model.predict(valid)\n",
        "      predicted = model.predict(x_test)\n",
        "\n",
        "    meta_model = meta.fit(meta_mtrx, valid_true)\n",
        "    meta_mtrx_test = np.empty((x_test.shape[0], len(models))) \n",
        "\n",
        "    for n, model in enumerate(models):\n",
        "        meta_mtrx_test[:, n] = model.predict(x_test)\n",
        "        \n",
        "    meta_predict = meta.predict(meta_mtrx_test)\n",
        "\n",
        "    return roc_auc_score(y_test, meta_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMaQZPnxNqBr"
      },
      "source": [
        "### 1.\n",
        "В следующей ячейке в теле функции определен условный оператор if-else. После elif вместо pass пропишите код из лекции с некоторыми новыми вставками в таком порядке: деление data_train и targets_train на тренировочные и валидационные данные с помощью функции train_test_split, где test_size=test_size из определения функции; определение матрицы meta_mtrx; цикл, в котором заполняется meta_mtrx: сначала строка, где модель обучается с помощью метода fit на тренировочных данных из разбиения, затем строка, где матрица заполняется значениями предсказаний моделей на валидационных данных. На этом цикл заканчивается.\n",
        "\n",
        "После цикла добавьте строку с методом fit мета-алгоритма: обучите его на значениях полученной матрицы meta_mtrx и целевой переменной для валидационных данных.\n",
        "\n",
        "Определите матрицу meta_mtrx_test. Напишите цикл, где эта матрица заполняется предсказаниями базовых моделей на тестовых данных data_test.\n",
        "\n",
        "После цикла сделайте предсказания мета-алгоритма для значений матрицы meta_mtrx_test.\n",
        "\n",
        "Дополните код еще одним оператором if, который будет проверять, существуют ли данные targets_test для проверки качества работы модели на тестовых данных: если targets_test не является None, тогда выведите метрику roc_auc_score для предсказаний мета-алгоритма на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0dJcqB5NqBr"
      },
      "source": [
        "def stacking(models, meta_alg, data_train, targets_train, data_test, \n",
        "             targets_test=None, random_state=None, test_size=None, cv=5):\n",
        "    \n",
        "  if test_size is None:\n",
        "      \n",
        "      from sklearn.model_selection import cross_val_predict\n",
        "      \n",
        "      meta_mtrx = np.empty((data_train.shape[0], len(models)))\n",
        "      \n",
        "      for n, model in enumerate(models):\n",
        "          meta_mtrx[:, n] = cross_val_predict(model, data_train, targets_train, \n",
        "                                              cv=5, method='predict')\n",
        "          model.fit(data_train, targets_train)\n",
        "          \n",
        "      meta_alg.fit(meta_mtrx, targets_train)\n",
        "      \n",
        "      meta_mtrx_test = np.empty((data_test.shape[0], len(models))) \n",
        "          \n",
        "      for n, model in enumerate(models):\n",
        "          meta_mtrx_test[:, n] = model.predict(data_test)\n",
        "      \n",
        "      print('test_size=None')\n",
        "      print('meta_mtrx_test predict:\\n', meta_alg.predict(meta_mtrx_test))\n",
        "\n",
        "  elif test_size > 0 and test_size < 1:\n",
        "      \n",
        "      x_train, x_valid, y_train, y_valid = train_test_split(data_train, \n",
        "                                                            targets_train, \n",
        "                                                            test_size=test_size)\n",
        "\n",
        "      meta_mtrx = np.empty((x_valid.shape[0], len(models)))\n",
        "      \n",
        "      for n, model in enumerate(models):\n",
        "          model.fit(x_train, y_train)\n",
        "          meta_mtrx[:, n] = model.predict(x_valid)\n",
        "\n",
        "      meta_alg.fit(meta_mtrx, y_valid)\n",
        "\n",
        "      meta_mtrx_test = np.empty((data_test.shape[0], len(models))) \n",
        "\n",
        "      for n, model in enumerate(models):\n",
        "          meta_mtrx_test[:, n] = model.predict(data_test)\n",
        "          \n",
        "      print('meta_mtrx_test predict:\\n', meta_alg.predict(meta_mtrx_test))\n",
        "\n",
        "  else:\n",
        "    # Об этом коде пошла речь только когда уже нужно было тестировать функцию!\n",
        "    raise ValueError('test_size must be between 0 and 1')\n",
        "      \n",
        "  if targets_test is not None:\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    print('targets_test roc_auc score:', roc_auc_score(targets_test, \n",
        "                                          meta_alg.predict(meta_mtrx_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ7ssAZ-NqBu"
      },
      "source": [
        "### 2.\n",
        "Теперь напишите код стекинга вместо pass после оператора if.\n",
        "\n",
        "Сразу определите матрицу meta_mtrx. Напишите цикл для заполнения матрицы: сначала напишите строку, где каждый столбец метапризнаков (для каждой модели) заполняется с помощью функции cross_val_predict(base_algotithm, data_train, targets_train, cv, method='predict'); следующая строка - обучите каждый базовый алгоритм на полном тренировочном датасете.\n",
        "\n",
        "После цикла обучите мета-алгоритм на матрице метапризнаков meta_mtrx. Определите матрицу meta_mtrx_test.\n",
        "\n",
        "Напишите второй цикл, где матрица meta_mtrx_test заполняется предсказаниями базовых моделей на тестовых данных data_test.\n",
        "\n",
        "После цикла сделайте предсказания мета-алгоритма для значений матрицы meta_mtrx_test.\n",
        "\n",
        "Так же, как и для блендинга, напишите код проверки для targets_test и выведите roc_auc_score, если это возможно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aYbDelYNqBu"
      },
      "source": [
        "# ваш код\n",
        "\n",
        "# Я так понял, что код должен был попасть в ункцию выше.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktP_ZympNqBx"
      },
      "source": [
        "### 3.\n",
        "Базовая функция стекинга готова. Теперь проверим, как она работает. Ниже представлен уже знакомый нам датасет Titanic, разделенный на тренировочный и тестовый датасеты; предопределенные базовые алгоритмы и мета-алгоритм. Ваша задача - составить список базовых алгоритмов и запустить функцию в трех различных вариантах (при этом в каждом из них все значения data_train, targets_train, data_test, targets_test должны быть определены):\n",
        "\n",
        "1. Вызвать исключение \"test_size must be between 0 and 1\".\n",
        "\n",
        "2. Установить test_size=0.3; вывести AUC и массив полученных предсказаний.\n",
        "\n",
        "3. Оставить test_size=None; вывести AUC и массив полученных предсказаний."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kJT4LjRNqBx"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "titanic = pd.read_csv('sample_data/titanic.csv')\n",
        "targets = titanic.Survived\n",
        "data = titanic.drop(columns='Survived')\n",
        "\n",
        "data['Sex'].replace(['female','male'],[0,1],inplace=True)\n",
        "# data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data[['PassengerId', \n",
        "                                                          'Pclass', 'Sex', \n",
        "                                                          'Age', 'SibSp', \n",
        "                                                          'Parch']].fillna(0), \n",
        "                                                    targets,\n",
        "                                                    train_size=0.8,\n",
        "                                                    random_state=17)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "lr = LogisticRegression(random_state=17)\n",
        "svc = SVC(random_state=17)\n",
        "\n",
        "meta = XGBClassifier(n_estimators=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbHZDCAiNqB0"
      },
      "source": [
        "# ваш код\n",
        "\n",
        "base_algos = [knn, lr, svc]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "XnSpFCNOmMN6",
        "outputId": "abb155ad-08e4-41dd-cbdd-6402c57a6f7a"
      },
      "source": [
        "stacking(\n",
        "    models = base_algos, \n",
        "    meta_alg = meta,\n",
        "    data_train = x_train,\n",
        "    targets_train = y_train,\n",
        "    data_test = x_test,\n",
        "    targets_test = y_test,\n",
        "    random_state = 42,\n",
        "    test_size = 2\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c05ce2b172f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtargets_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-34-7564cb3a1f47>\u001b[0m in \u001b[0;36mstacking\u001b[0;34m(models, meta_alg, data_train, targets_train, data_test, targets_test, random_state, test_size, cv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;31m# Об этом коде пошла речь только когда уже нужно было тестировать функцию!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_size must be between 0 and 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtargets_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: test_size must be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPZP82xbmVBt",
        "outputId": "c0dfcb4c-8c95-4324-c792-ebf84a7bb0c7"
      },
      "source": [
        "stacking(\n",
        "    models = base_algos, \n",
        "    meta_alg = meta,\n",
        "    data_train = x_train,\n",
        "    targets_train = y_train,\n",
        "    data_test = x_test,\n",
        "    targets_test = y_test,\n",
        "    random_state = 42,\n",
        "    test_size = 0.3\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "meta_mtrx_test predict:\n",
            " [0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0]\n",
            "targets_test roc_auc score: 0.7627293874386146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2wZTu0smgPZ",
        "outputId": "ceda6c81-289d-4b18-baab-d2ca9a8eba17"
      },
      "source": [
        "stacking(\n",
        "    models = base_algos, \n",
        "    meta_alg = meta,\n",
        "    data_train = x_train,\n",
        "    targets_train = y_train,\n",
        "    data_test = x_test,\n",
        "    targets_test = y_test,\n",
        "    random_state = 42\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_size=None\n",
            "meta_mtrx_test predict:\n",
            " [0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0\n",
            " 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0\n",
            " 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0\n",
            " 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0]\n",
            "targets_test roc_auc score: 0.7532954251744637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT9CNfbBNqB2"
      },
      "source": [
        "По мере того, как вы будете использовать эту функцию, вам могут пригодиться такие дополнительные параметры как: random_state, который позволит делать воспроизводимые модели; metrics - список метрик, которые могут быть вычислены; grid_search, который может производить поиск лучших параметров для алгоритмов, и т.д."
      ]
    }
  ]
}